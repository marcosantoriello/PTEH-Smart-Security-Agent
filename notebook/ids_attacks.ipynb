{
    "cells": [
        {
            "cell_type": "markdown",
            "id": "b3c8f8d1",
            "metadata": {},
            "source": [
                "# IDS Multiclass Attack Detection\n",
                "\n",
                "This notebook implements a multiclass Random Forest classifier for the CIC-IDS2017 dataset.\n",
                "It covers data exploration, preprocessing, model training, and evaluation."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "f8a7e3b1",
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "import os\n",
                "from typing import Tuple, List, Dict\n",
                "\n",
                "# Constants\n",
                "DATASET_PATH = '../dataset/combined_dataset.csv'\n",
                "OUTPUT_IMGS_PATH = '../assets/imgs/output_charts/'\n",
                "os.makedirs(OUTPUT_IMGS_PATH, exist_ok=True)\n",
                "\n",
                "pd.set_option('display.max_columns', None)\n",
                "pd.set_option('display.width', 1000)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "load_data_md",
            "metadata": {},
            "source": [
                "## 1. Data Loading"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "load_data_code",
            "metadata": {},
            "outputs": [],
            "source": [
                "def load_data(dataset_path: str) -> pd.DataFrame:\n",
                "    \"\"\"\n",
                "    Load the specified dataset and returns it.\n",
                "    :param str dataset_path: The path to the dataset to import.\n",
                "    :return: pd.DataFrame containing the imported dataset.\n",
                "    \"\"\"\n",
                "    print(f\"[INFO] Loading dataset from {dataset_path}...\")\n",
                "    df = pd.read_csv(dataset_path, low_memory=False)\n",
                "\n",
                "    string_cols = ['flow_id', 'timestamp', 'src_ip', 'dst_ip', 'protocol', 'label']\n",
                "    \n",
                "    for col in df.columns:\n",
                "        if col not in string_cols:\n",
                "            df[col] = pd.to_numeric(df[col], errors='coerce')   \n",
                "    \n",
                "    print(f\"[INFO] Dataset loaded. Shape: {df.shape}\")\n",
                "    return df"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "eda_md",
            "metadata": {},
            "source": [
                "## 2. Data Exploration (EDA)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def plot_benign_vs_malicious(dataframe: pd.DataFrame) -> None:\n",
                "    \"\"\"\n",
                "    Plot the distribution of benign vs malicious samples in the dataset with a pie chart.\n",
                "\n",
                "    :param pd.DataFrame dataframe: The dataframe to analyze.\n",
                "    \"\"\"\n",
                "    fig, ax = plt.subplots()\n",
                "    ax.pie(dataframe['label'].value_counts(), labels=dataframe['label'].value_counts().index, autopct='%1.1f%%', startangle=90, colors=['#66b3ff','#ff9999'])\n",
                "    ax.set_title('Benign vs Malicious Distribution')\n",
                "    plt.savefig(f'{OUTPUT_IMGS_PATH}/benign_vs_malicious_distribution.png', dpi=200)\n",
                "    plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "check_nans",
            "metadata": {},
            "outputs": [],
            "source": [
                "def check_for_nans_and_duplicates(dataframe: pd.DataFrame) -> Tuple[pd.DataFrame, pd.Series]:\n",
                "    \"\"\"\n",
                "    Check for duplicates and NaN values.\n",
                "    \"\"\"\n",
                "    duplicates = dataframe[dataframe.duplicated()]\n",
                "    print(f\"N. of duplicates: {duplicates.shape[0]}\")\n",
                "    \n",
                "    nan_summary = dataframe.isna().sum()\n",
                "    nan_columns = nan_summary[nan_summary > 0]\n",
                "    print(f\"\\nColumns with NaNs: {len(nan_columns)}\")\n",
                "    if not nan_columns.empty:\n",
                "        print(nan_columns)\n",
                "    \n",
                "    return duplicates, nan_summary"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "plot_dist",
            "metadata": {},
            "outputs": [],
            "source": [
                "def plot_attacks_distribution(dataframe: pd.DataFrame, target_column: str) -> None:\n",
                "    \"\"\"\n",
                "    Plot the distribution of the attack types.\n",
                "    \"\"\"\n",
                "    plt.figure(figsize=(12, 6))\n",
                "    sns.countplot(data=dataframe, x=target_column, order=dataframe[target_column].value_counts().index)\n",
                "    plt.title('Attack Type Distribution', fontsize=15)\n",
                "    plt.xlabel('Attack Classes', fontsize=12)\n",
                "    plt.ylabel('Count', fontsize=12)\n",
                "    plt.xticks(rotation=45, ha='right')\n",
                "    plt.tight_layout()\n",
                "    plt.savefig(f'{OUTPUT_IMGS_PATH}attack_distribution.png', dpi=200)\n",
                "    plt.show()\n",
                "\n",
                "def plot_class_breakdown_pie(y: np.ndarray, labels: list) -> None:\n",
                "    \"\"\"Plot a pie chart of the class distribution.\"\"\"\n",
                "    counts = pd.Series(y).value_counts().sort_index()\n",
                "    class_labels = [labels[i] for i in counts.index]\n",
                "    \n",
                "    plt.figure(figsize=(12, 12))\n",
                "    \n",
                "    # Only show percentage if > 2% to obtain readable labels\n",
                "    def make_autopct(pct):\n",
                "        return ('%1.1f%%' % pct) if pct > 2.0 else ''\n",
                "    \n",
                "    plt.pie(counts, labels=None, autopct=make_autopct, startangle=140, pctdistance=0.85)\n",
                "    plt.legend(class_labels, title=\"Attack Types\", loc=\"center left\", bbox_to_anchor=(1, 0, 0.5, 1))\n",
                "    plt.title('Attack Class Distribution (Percentage)', fontsize=15)\n",
                "    plt.tight_layout()\n",
                "    plt.savefig(f'{OUTPUT_IMGS_PATH}class_distribution_pie.png', dpi=200)\n",
                "    plt.show()\n",
                "\n",
                "def plot_correlation_heatmap(df: pd.DataFrame, title: str = \"Feature Correlation Matrix\") -> None:\n",
                "    \"\"\"Plot a correlation heatmap for the DataFrame.\"\"\"\n",
                "    corr = df.corr()\n",
                "    plt.figure(figsize=(20, 16))\n",
                "    sns.heatmap(corr, annot=False, cmap='coolwarm', linewidths=0.5)\n",
                "    plt.title(title, fontsize=15)\n",
                "    plt.tight_layout()\n",
                "    plt.savefig(f'{OUTPUT_IMGS_PATH}correlation_matrix_{title.replace(\" \", \"_\")}.png', dpi=200)\n",
                "    plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def plot_dataset_comparision(len_before: int, len_after: int) -> None:\n",
                "    \"\"\"\n",
                "    Plot a comparison of dataset size before and after cleaning.\n",
                "\n",
                "    :param int len_before: Length of the dataset before cleaning.\n",
                "    :param int len_after: Length of the dataset after cleaning.\n",
                "    \"\"\"\n",
                "    labels = [\"Before Cleaning\", \"After Cleaning\"]\n",
                "    values = [len_before, len_after]\n",
                "\n",
                "    plt.figure(figsize=(8, 5))\n",
                "    bars = plt.bar(labels, values, color=['lightblue', 'orange'])\n",
                "\n",
                "    plt.title(\"Dataset Size Before and After Cleaning\")\n",
                "    plt.ylabel(\"Number of Samples\")\n",
                "\n",
                "    # numeric labels\n",
                "    try:\n",
                "        plt.bar_label(bars, labels=[str(v) for v in values], padding=3)\n",
                "    except AttributeError:\n",
                "        for rect, v in zip(bars, values):\n",
                "            x = rect.get_x() + rect.get_width() / 2\n",
                "            y = rect.get_height()\n",
                "            plt.text(x, y, str(v), ha=\"center\", va=\"bottom\")\n",
                "\n",
                "    plt.tight_layout()\n",
                "    plt.savefig(f'{OUTPUT_IMGS_PATH}dataset_size_comparison.png', dpi=200)\n",
                "    plt.show()\n",
                "    plt.close()"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "cleaning_md",
            "metadata": {},
            "source": [
                "## 3. Data Cleaning & Preprocessing"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "clean_data_code",
            "metadata": {},
            "outputs": [],
            "source": [
                "def clean_data(dataset: pd.DataFrame, columns_to_remove: List[str]) -> Tuple[pd.DataFrame, pd.Series]:\n",
                "    \"\"\"\n",
                "    Clean dataset: remove duplicates, handle NaNs, drop irrelevant columns.\n",
                "    Returns X (features) and y (target).\n",
                "    \"\"\"\n",
                "    print(\"[INFO] Cleaning data...\")\n",
                "    dataset = dataset.drop_duplicates()\n",
                "    dataset = dataset.replace([np.inf, -np.inf], np.nan)\n",
                "    dataset = dataset.dropna()\n",
                "    \n",
                "    # Drop irrelevant columns\n",
                "    existing_cols_to_drop = [c for c in columns_to_remove if c in dataset.columns]\n",
                "    dataset = dataset.drop(columns=existing_cols_to_drop)\n",
                "\n",
                "    # Round floats\n",
                "    float_cols = dataset.select_dtypes(include=['float']).columns\n",
                "    dataset[float_cols] = dataset[float_cols].round(4)\n",
                "\n",
                "    # Separate X and y\n",
                "    y = dataset['label']\n",
                "    X = dataset.drop(columns=['label'])\n",
                "    \n",
                "    print(f\"[INFO] Data cleaned. Features: {X.shape[1]}, Samples: {X.shape[0]}\")\n",
                "    return X, y"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "encode_features",
            "metadata": {},
            "outputs": [],
            "source": [
                "from sklearn.preprocessing import LabelEncoder\n",
                "\n",
                "def encode_categorical_features(X: pd.DataFrame) -> Tuple[pd.DataFrame, LabelEncoder]:\n",
                "    \"\"\"\n",
                "    Encode 'protocol' column if present using LabelEncoder.\n",
                "    Returns encoded DataFrame and the encoder.\n",
                "    \"\"\"\n",
                "    X_encoded = X.copy()\n",
                "    le = LabelEncoder()\n",
                "    \n",
                "    if 'protocol' in X_encoded.columns:\n",
                "        print(\"[INFO] Encoding 'protocol' column...\")\n",
                "        # Ensure protocol is string for encoding\n",
                "        X_encoded['protocol'] = X_encoded['protocol'].astype(str)\n",
                "        X_encoded['protocol'] = le.fit_transform(X_encoded['protocol'])\n",
                "        print(f\"       Unique protocols encoded: {le.classes_}\")\n",
                "    \n",
                "    return X_encoded, le"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "encode_target",
            "metadata": {},
            "outputs": [],
            "source": [
                "def encode_multiclass_labels(y: pd.Series) -> Tuple[np.ndarray, LabelEncoder]:\n",
                "    \"\"\"\n",
                "    Encode target labels for multiclass classification.\n",
                "    \"\"\"\n",
                "    le = LabelEncoder()\n",
                "    y_encoded = le.fit_transform(y)\n",
                "    \n",
                "    print(\"\\n\" + \"=\"*60)\n",
                "    print(\"MULTICLASS LABEL ENCODING SUMMARY \")\n",
                "    print(\"=\"*60)\n",
                "    for idx, cls in enumerate(le.classes_):\n",
                "        count = (y_encoded == idx).sum()\n",
                "        pct = (count / len(y_encoded)) * 100\n",
                "        print(f\" {idx:>2} | {cls:<25} | {count:>7} samples ({pct:>5.2f}%)\")\n",
                "    print(\"=\"*60 + \"\\n\")\n",
                "    \n",
                "    return y_encoded, le"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "split_data",
            "metadata": {},
            "outputs": [],
            "source": [
                "from sklearn.model_selection import train_test_split\n",
                "\n",
                "def split_dataset(X: pd.DataFrame, y: np.ndarray, test_size: float = 0.2, random_state: int = 42):\n",
                "    \"\"\"\n",
                "    Stratified split of the dataset.\n",
                "    \"\"\"\n",
                "    print(f\"[INFO] Splitting dataset (test_size={test_size})...\")\n",
                "    return train_test_split(X, y, test_size=test_size, random_state=random_state, stratify=y)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "feature_eng_md",
            "metadata": {},
            "source": [
                "## 4. Feature Engineering & Selection"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "feature_selection",
            "metadata": {},
            "outputs": [],
            "source": [
                "from sklearn.feature_selection import VarianceThreshold\n",
                "from sklearn.feature_selection import SelectKBest, mutual_info_classif\n",
                "from sklearn.ensemble import RandomForestClassifier\n",
                "from sklearn.preprocessing import StandardScaler\n",
                "\n",
                "def remove_low_variance_features(X: pd.DataFrame, threshold: float = 0.01) -> pd.DataFrame:\n",
                "    \"\"\"Remove features with variance lower than threshold.\"\"\"\n",
                "    print(f\"[INFO] Removing low variance features (threshold={threshold})...\")\n",
                "    selector = VarianceThreshold(threshold=threshold)\n",
                "    selector.fit(X)\n",
                "    X_new = X.loc[:, selector.get_support()]\n",
                "    print(f\"       Removed {X.shape[1] - X_new.shape[1]} features. Remaining: {X_new.shape[1]}\")\n",
                "    return X_new\n",
                "\n",
                "def remove_correlated_features(X: pd.DataFrame, threshold: float = 0.95) -> pd.DataFrame:\n",
                "    \"\"\"Remove highly correlated features (Pearson > threshold).\"\"\"\n",
                "    print(f\"[INFO] Removing correlated features (threshold={threshold})...\")\n",
                "    corr_matrix = X.corr().abs()\n",
                "    upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
                "    to_drop = [column for column in upper.columns if any(upper[column] > threshold)]\n",
                "    \n",
                "    X_new = X.drop(columns=to_drop)\n",
                "    print(f\"       Removed {len(to_drop)} features. Remaining: {X_new.shape[1]}\")\n",
                "    return X_new\n",
                "\n",
                "def select_top_features_rf(X: pd.DataFrame, y: np.ndarray, k: int = 40, subsample_size: int = 50000) -> Tuple[pd.DataFrame, List[str]]:\n",
                "    \"\"\"\n",
                "    Select top K features using Random Forest Feature Importance.\n",
                "    Uses a stratified subsample for efficiency.\n",
                "    \"\"\"\n",
                "    k = min(k, X.shape[1])\n",
                "    print(f\"[INFO] Selecting top {k} features using Random Forest Importance...\")\n",
                "    \n",
                "    # Subsample for speed if dataset is extensive\n",
                "    if len(X) > subsample_size:\n",
                "        print(f\"       Using subsample of {subsample_size} for feature selection...\")\n",
                "        X_sub, _, y_sub, _ = train_test_split(X, y, train_size=subsample_size, stratify=y, random_state=42)\n",
                "    else:\n",
                "        X_sub, y_sub = X, y\n",
                "        \n",
                "    rf = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
                "    rf.fit(X_sub, y_sub)\n",
                "    \n",
                "    importances = rf.feature_importances_\n",
                "    indices = np.argsort(importances)[::-1]\n",
                "    \n",
                "    top_indices = indices[:k]\n",
                "    selected_features = X.columns[top_indices].tolist()\n",
                "    \n",
                "    print(f\"       Selected Features: {selected_features}\")\n",
                "    \n",
                "    return X[selected_features], selected_features\n",
                "\n",
                "def scale_data(X_train: pd.DataFrame, X_test: pd.DataFrame) -> Tuple[pd.DataFrame, pd.DataFrame, StandardScaler]:\n",
                "    \"\"\"Scale data using StandardScaler.\"\"\"\n",
                "    print(\"[INFO] Scaling features (StandardScaler)...\")\n",
                "    scaler = StandardScaler()\n",
                "    X_train_scaled = pd.DataFrame(scaler.fit_transform(X_train), columns=X_train.columns, index=X_train.index)\n",
                "    X_test_scaled = pd.DataFrame(scaler.transform(X_test), columns=X_test.columns, index=X_test.index)\n",
                "    return X_train_scaled, X_test_scaled, scaler"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "model_training_md",
            "metadata": {},
            "source": [
                "## 5. Model Training & Evaluation"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "train_evaluate_model",
            "metadata": {},
            "outputs": [],
            "source": [
                "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, f1_score\n",
                "\n",
                "def train_model(X_train: pd.DataFrame, y_train: np.ndarray) -> RandomForestClassifier:\n",
                "    \"\"\"\n",
                "    Train Random Forest Classifier.\n",
                "    \"\"\"\n",
                "    print(\"[INFO] Training Random Forest Classifier...\")\n",
                "    rf_model = RandomForestClassifier(\n",
                "        n_estimators=100, \n",
                "        max_depth=None, \n",
                "        min_samples_split=2, \n",
                "        min_samples_leaf=1,\n",
                "        random_state=42, \n",
                "        n_jobs=-1\n",
                "    )\n",
                "    rf_model.fit(X_train, y_train)\n",
                "    print(\"[INFO] Training complete.\")\n",
                "    return rf_model\n",
                "\n",
                "def evaluate_model(model: RandomForestClassifier, X_test: pd.DataFrame, y_test: np.ndarray, label_encoder: LabelEncoder) -> None:\n",
                "    \"\"\"\n",
                "    Evaluate the model on the test set and plot confusion matrix.\n",
                "    \"\"\"\n",
                "    print(\"[INFO] Evaluating model on test set...\")\n",
                "    y_pred = model.predict(X_test)\n",
                "    \n",
                "    # Metrics\n",
                "    accuracy = accuracy_score(y_test, y_pred)\n",
                "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
                "    \n",
                "    print(f\"\\n{'='*40}\")\n",
                "    print(f\"MODEL EVALUATION\")\n",
                "    print(f\"{'='*40}\")\n",
                "    print(f\"Accuracy:  {accuracy:.4f}\")\n",
                "    print(f\"F1 Score:  {f1:.4f}\")\n",
                "    print(f\"{'='*40}\\n\")\n",
                "    \n",
                "    print(\"Classification Report:\")\n",
                "    print(classification_report(y_test, y_pred, target_names=label_encoder.classes_))\n",
                "    \n",
                "    # Confusion Matrix\n",
                "    cm = confusion_matrix(y_test, y_pred)\n",
                "    plt.figure(figsize=(16, 14))\n",
                "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
                "                xticklabels=label_encoder.classes_, \n",
                "                yticklabels=label_encoder.classes_)\n",
                "    plt.title('Multiclass Confusion Matrix', fontsize=15)\n",
                "    plt.xlabel('Predicted Label', fontsize=12)\n",
                "    plt.ylabel('True Label', fontsize=12)\n",
                "    plt.xticks(rotation=45, ha='right')\n",
                "    plt.tight_layout()\n",
                "    plt.savefig(f'{OUTPUT_IMGS_PATH}confusion_matrix.png', dpi=200)\n",
                "    plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "param_tuning_md",
            "metadata": {},
            "source": [
                "## 6. Hyperparameter Tuning (NEW)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "hyperparameter_tuning",
            "metadata": {},
            "outputs": [],
            "source": [
                "from sklearn.model_selection import RandomizedSearchCV\n",
                "\n",
                "def optimize_model(X_train: pd.DataFrame, y_train: np.ndarray) -> RandomForestClassifier:\n",
                "    \"\"\"\n",
                "    Perform hyperparameter tuning using RandomizedSearchCV on a subsample of data.\n",
                "    \"\"\"\n",
                "    print(f\"\\n{'='*40}\")\n",
                "    print(f\"HYPERPARAMETER TUNING (RandomizedSearchCV)\")\n",
                "    print(f\"{'='*40}\")\n",
                "    \n",
                "    # 1. Subsample for speed (e.g., 50k samples)\n",
                "    subsample_size = 50000\n",
                "    if len(X_train) > subsample_size:\n",
                "        print(f\"[INFO] Subsampling {subsample_size} records for tuning... (Stratified)\")\n",
                "        X_tune, _, y_tune, _ = train_test_split(X_train, y_train, train_size=subsample_size, stratify=y_train, random_state=42)\n",
                "    else:\n",
                "        X_tune, y_tune = X_train, y_train\n",
                "        \n",
                "    # 2. Define Parameter Grid\n",
                "    param_dist = {\n",
                "        'n_estimators': [100, 200, 300],\n",
                "        'max_depth': [None, 20, 30, 40],\n",
                "        'min_samples_split': [2, 5, 10],\n",
                "        'min_samples_leaf': [1, 2, 4],\n",
                "        'max_features': ['sqrt', 'log2', None]\n",
                "    }\n",
                "    \n",
                "    # 3. Randomized Search\n",
                "    rf = RandomForestClassifier(random_state=42, n_jobs=-1)\n",
                "    \n",
                "    random_search = RandomizedSearchCV(\n",
                "        estimator=rf,\n",
                "        param_distributions=param_dist,\n",
                "        n_iter=10,        # Number of parameter settings to sample\n",
                "        cv=3,             # 3-fold CV for speed\n",
                "        scoring='f1_weighted',\n",
                "        verbose=2,\n",
                "        random_state=42,\n",
                "        n_jobs=-1\n",
                "    )\n",
                "    \n",
                "    print(\"[INFO] Starting search...\")\n",
                "    random_search.fit(X_tune, y_tune)\n",
                "    \n",
                "    print(f\"\\nBest Parameters: {random_search.best_params_}\")\n",
                "    print(f\"Best CV Score: {random_search.best_score_:.4f}\")\n",
                "    \n",
                "    # 4. Retrain on FULL train set with best params\n",
                "    print(\"\\n[INFO] Retraining model on FULL training set with best parameters...\")\n",
                "    best_model = random_search.best_estimator_\n",
                "    best_model.fit(X_train, y_train)\n",
                "    \n",
                "    return best_model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def save_model(model, label_encoder, scaler, selected_features, protocol_encoder, filepath='./models/v2/ids_model.joblib'):\n",
                "    \"\"\"\n",
                "    Save the trained model and associated artifacts in a single package using joblib.\n",
                "    \"\"\"\n",
                "    import joblib\n",
                "    import os\n",
                "    \n",
                "    print(f\"[INFO] Saving model package to {filepath}...\")\n",
                "    # Create directory if not exists\n",
                "    os.makedirs(os.path.dirname(filepath), exist_ok=True)\n",
                "    \n",
                "    # Package everything\n",
                "    model_package = {\n",
                "        'model': model,\n",
                "        'label_encoder': label_encoder,\n",
                "        'scaler': scaler,\n",
                "        'selected_features': selected_features,\n",
                "        'protocol_encoder': protocol_encoder\n",
                "    }\n",
                "    \n",
                "    # Save\n",
                "    joblib.dump(model_package, filepath)\n",
                "    \n",
                "    print(f\"[SUCCESS] Model saved to: {filepath}\")\n",
                "    print(f\"          Contains: model, label_encoder, scaler, selected_features, protocol_encoder\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "main_execution",
            "metadata": {},
            "outputs": [],
            "source": [
                "if __name__ == '__main__':\n",
                "    \n",
                "    if os.path.exists(DATASET_PATH):\n",
                "        df = load_data(DATASET_PATH)\n",
                "\n",
                "        len_before = len(df)\n",
                "        \n",
                "        # EDA\n",
                "        plot_attacks_distribution(df, 'label')\n",
                "        check_for_nans_and_duplicates(df)\n",
                "        cols_to_remove = ['flow_id', 'src_ip', 'src_port', 'dst_ip', 'timestamp']\n",
                "        X_clean, y_clean = clean_data(df, cols_to_remove)\n",
                "\n",
                "        len_after = len(X_clean)\n",
                "        plot_dataset_comparision(len_before, len_after)\n",
                "\n",
                "        \n",
                "        X_encoded, protocol_encoder = encode_categorical_features(X_clean)\n",
                "        y_multiclass, label_encoder = encode_multiclass_labels(y_clean)\n",
                "        \n",
                "        # EDA - Additional Visualizations\n",
                "        plot_class_breakdown_pie(y_multiclass, label_encoder.classes_)\n",
                "        \n",
                "        # Split (Stratified)\n",
                "        X_train, X_test, y_train, y_test = split_dataset(X_encoded, y_multiclass)\n",
                "        print(f\"Training Set: {X_train.shape}\")\n",
                "\n",
                "        plot_correlation_heatmap(X_train, title=\"Correlation Matrix (Pre-Removal)\")\n",
                "        \n",
                "        \n",
                "        # 1. Remove Low Variance\n",
                "        X_train_lv = remove_low_variance_features(X_train)\n",
                "        X_test_lv = X_test[X_train_lv.columns]\n",
                "        \n",
                "        # 2. Remove Correlated\n",
                "        X_train_corr = remove_correlated_features(X_train_lv)\n",
                "        X_test_corr = X_test_lv[X_train_corr.columns]\n",
                "\n",
                "        plot_correlation_heatmap(X_train_corr, title=\"Correlation Matrix (Post-Removal)\")\n",
                "        \n",
                "        # 3. Feature Selection (Random Forest)\n",
                "        X_train_selected, selected_feats = select_top_features_rf(X_train_corr, y_train, k=40)\n",
                "        X_test_selected = X_test_corr[selected_feats]\n",
                "        \n",
                "        # 4. Scale Data\n",
                "        X_train_scaled, X_test_scaled, scaler = scale_data(X_train_selected, X_test_selected)\n",
                "        \n",
                "        print(f\"Train Shape: {X_train_scaled.shape}\")\n",
                "        \n",
                "        print(\"\\n--- Running Hyperparameter Optimization ---\")\n",
                "        rf_optimized = optimize_model(X_train_scaled, y_train)\n",
                "        \n",
                "        print(\"\\n[INFO] Evaluating Optimized Model...\")\n",
                "        evaluate_model(rf_optimized, X_test_scaled, y_test, label_encoder)\n",
                "        \n",
                "        print(\"\\n[INFO] Saving the model...\")\n",
                "        save_model(rf_optimized, label_encoder, scaler, selected_feats, protocol_encoder)\n",
                "    else:\n",
                "        print(f\"[ERROR] Dataset not found at {DATASET_PATH}\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "mlVenv",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.13.3"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
